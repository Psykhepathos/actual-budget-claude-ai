# ü§ñ Actual Budget - Fork Pessoal com Testes de IA

Este √© um **fork pessoal** do [Actual Budget](https://github.com/actualbudget/actual) para **testes locais** e experimenta√ß√£o com funcionalidades de IA.

> ‚ö†Ô∏è **Este √© um reposit√≥rio de testes pessoais** - Para usar o Actual Budget oficial, acesse: https://github.com/actualbudget/actual

## üìù Sobre este Fork

Este fork inclui:
- ‚úÖ **Actual Budget completo** (vers√£o original)
- üß™ **Experimentos com IA** para classifica√ß√£o de transa√ß√µes
- üîß **Ambiente de desenvolvimento** personalizado
- üê≥ **Setup Docker** para testes locais

## üéØ Objetivo

Este fork experimenta a integra√ß√£o de **IA para classifica√ß√£o autom√°tica de transa√ß√µes** no Actual Budget. O sistema usa um microservi√ßo proxy que conecta o [actual-ai addon](https://github.com/actualbudget/actual-ai) com o seu ambiente local, permitindo classifica√ß√£o inteligente sem necessidade de API keys externas.

## üöÄ Como Usar

### Pr√©-requisitos
- **Node.js 20+** e **Yarn 4.9.1+**
- **Docker** (obrigat√≥rio para funcionalidades de IA)
- **Actual AI Addon** dispon√≠vel via Docker

### Setup B√°sico (Sem IA)
```bash
git clone https://github.com/Psykhepathos/actual-budget-claude-ai.git
cd actual-budget-claude-ai
yarn install
yarn start
```

### Setup Completo com IA (Recomendado)

#### 1. Configure Vari√°veis de Ambiente
```bash
# Copie o arquivo de exemplo
cp .env.addon.example .env.addon

# Edite com suas configura√ß√µes
# Windows: notepad .env.addon
# Mac/Linux: nano .env.addon
```

**Arquivo `.env.addon` - Configure apenas:**
```env
# Configura√ß√µes do Actual Budget
ACTUAL_PASSWORD=sua_senha_aqui
ACTUAL_BUDGET_ID=  # Voc√™ vai obter depois

# Configura√ß√£o do Claude Code Proxy (sem API key necess√°ria!)
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434

# Features (comece com dry run para testar)
FEATURES=["dryRun"]
```

#### 2. Instale Depend√™ncias e Inicie
```bash
# Instalar depend√™ncias (primeira vez)
yarn install

# Iniciar Actual + Claude Code Proxy + AI Addon
yarn start:server-dev-ai
```

#### 3. Configure o Actual Budget
1. **Acesse**: http://localhost:5006
2. **Crie uma conta** com a senha do `.env.addon`
3. **Configure categorias** (ex: Alimenta√ß√£o, Transporte, Lazer...)
4. **V√° em Configura√ß√µes** ‚Üí "Show advanced settings"
5. **Copie o Sync ID** (Budget ID)
6. **Cole no `.env.addon`**:
   ```env
   ACTUAL_BUDGET_ID=eb97472d-2bb9-4679-ac40-ba7c01e9d591
   ```

#### 4. Reinicie o AI e Teste
```bash
# Reiniciar AI com novas configura√ß√µes
yarn ai:dev:restart

# Monitorar logs em tempo real
yarn ai:dev:logs
```

#### 5. Teste a Classifica√ß√£o
1. **Adicione transa√ß√µes** sem categoria
2. **Aguarde 5 minutos** (intervalo de desenvolvimento)
3. **Verifique** se apareceram tags `#dev-ai-classified`
4. **Sucesso!** üéâ

## üîß Microservi√ßos e Componentes

### ü§ñ Claude Code Proxy
Localizado em `./claude-code-proxy/`

**O que faz**: Converte sua sess√£o local em uma API compat√≠vel com Ollama para o actual-ai addon

**Porta**: 11434 (mesma do Ollama)

**Como funciona**:
- Usa o CLI local instalado
- N√£o precisa de API keys
- Simula API do Ollama para compatibilidade

### üß† Actual AI Addon
**Reposit√≥rio**: https://github.com/actualbudget/actual-ai
**Imagem Docker**: `actualbudget/actual-ai:latest`
**Documenta√ß√£o**: https://github.com/actualbudget/actual-ai#readme

**O que faz**: Addon oficial que conecta com LLMs para classificar transa√ß√µes automaticamente

**Configura√ß√£o no docker-compose.dev.yml**:
```yaml
actual-ai-dev:
  image: actualbudget/actual-ai:latest
  environment:
    - ACTUAL_SERVER_URL=http://actual-server:5006
    - OLLAMA_BASE_URL=http://claude-code-proxy:11434  # Aponta para nosso proxy
    - ACTUAL_PASSWORD=${ACTUAL_PASSWORD}              # Do .env.addon
    - ACTUAL_BUDGET_ID=${ACTUAL_BUDGET_ID}           # Do .env.addon
    - LLM_PROVIDER=ollama                            # Usa "ollama" mas √© nosso proxy
    - FEATURES=["dryRun"]                            # Modo seguro por padr√£o
    - CLASSIFICATION_INTERVAL=300000                 # 5 min (desenvolvimento)
    - LOG_LEVEL=info                                 # Logs detalhados
    - MAX_TRANSACTIONS_PER_RUN=50                    # Limite por execu√ß√£o
```

**Vari√°veis de Ambiente Dispon√≠veis**:
- `ACTUAL_SERVER_URL` - URL do servidor Actual Budget
- `ACTUAL_PASSWORD` - Senha do arquivo do Actual
- `ACTUAL_BUDGET_ID` - ID do or√ßamento (Sync ID)
- `LLM_PROVIDER` - Provedor de LLM (`openai`, `anthropic`, `ollama`)
- `OLLAMA_BASE_URL` - URL base do Ollama/Proxy
- `OPENAI_API_KEY` - Chave da OpenAI (se usar)
- `ANTHROPIC_API_KEY` - Chave da Anthropic (se usar)
- `FEATURES` - Array de features (`["dryRun"]` para teste)
- `CLASSIFICATION_INTERVAL` - Intervalo em ms (padr√£o: 300000 = 5min)
- `LOG_LEVEL` - N√≠vel de log (`debug`, `info`, `warn`, `error`)
- `MAX_TRANSACTIONS_PER_RUN` - M√°ximo de transa√ß√µes por execu√ß√£o
- `RETRY_ATTEMPTS` - Tentativas de retry em caso de erro
- `CATEGORIES_CACHE_TTL` - TTL do cache de categorias

### üê≥ Docker Services
```bash
# Ver status dos containers
docker ps

# Logs do AI addon
yarn ai:dev:logs

# Logs do proxy
docker-compose -f docker-compose.dev.yml logs claude-code-proxy

# Restart espec√≠fico
yarn ai:dev:restart

# Parar tudo
yarn ai:dev:stop
```

## üõ†Ô∏è Comandos √öteis

### Desenvolvimento
```bash
yarn start:server-dev-ai    # Actual + Proxy + AI (recomendado)
yarn start:server-dev       # Apenas Actual + Proxy
yarn start                  # Apenas Actual (sem AI)
```

### AI Addon Control
```bash
yarn ai:dev                 # Iniciar AI addon
yarn ai:dev:logs            # Ver logs em tempo real
yarn ai:dev:restart         # Reiniciar AI addon
yarn ai:dev:stop            # Parar AI addon
```

### Debug e Manuten√ß√£o
```bash
yarn typecheck             # Verificar tipos TypeScript
yarn lint:fix              # Corrigir c√≥digo automaticamente
yarn test                  # Executar testes

# Health checks
curl http://localhost:11434/health          # Proxy
curl http://localhost:5006                  # Actual Budget
```

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

### Modo Produ√ß√£o (Classifica√ß√£o Real)
```bash
# 1. Editar .env.addon
FEATURES=[]  # Remover "dryRun"

# 2. Reiniciar
yarn ai:dev:restart
```

### Intervalos Personalizados
```env
# No docker-compose.dev.yml, adicionar:
- CLASSIFICATION_INTERVAL=300000  # 5 minutos (padr√£o desenvolvimento)
# Para produ√ß√£o: 14400000 (4 horas)
```

### Providers Alternativos
Se quiser usar APIs externas ao inv√©s do proxy local:

#### ü§ñ OpenAI
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-proj-sua_chave_aqui
```
**Como obter chave**:
1. Acesse https://platform.openai.com/api-keys
2. Fa√ßa login/cadastro
3. Clique "Create new secret key"
4. Copie a chave (come√ßa com `sk-proj-`)

**Modelos suportados**: GPT-4, GPT-3.5-turbo
**Custo**: Pago por uso (~$0.03/1k tokens)

#### üß† Anthropic Claude
```env
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-sua_chave_aqui
```
**Como obter chave**:
1. Acesse https://console.anthropic.com/
2. Fa√ßa login/cadastro
3. V√° em "API Keys"
4. Clique "Create Key"
5. Copie a chave (come√ßa com `sk-ant-`)

**Modelos suportados**: Claude 3 (Sonnet, Haiku, Opus)
**Custo**: Pago por uso (~$0.015/1k tokens)

#### ü¶ô Ollama Local
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
```
**Como instalar**:
1. Baixe em https://ollama.ai/
2. Instale Ollama
3. Execute: `ollama pull llama2` (ou outro modelo)
4. Inicie: `ollama serve`

**Modelos suportados**: Llama2, Mistral, CodeLlama, etc.
**Custo**: Gratuito (roda local)

#### üîó Nossa Solu√ß√£o (Padr√£o)
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434  # Claude Code Proxy
```
**Vantagens**:
- ‚úÖ **Gratuito** (usa sua sess√£o local)
- ‚úÖ **Sem limites** de API
- ‚úÖ **Privacidade** total
- ‚úÖ **Setup zero** de chaves

## üö® Troubleshooting

### ‚ùå Containers n√£o sobem
```bash
# Verificar se Docker est√° rodando
docker --version

# Verificar portas em uso
netstat -an | findstr :5006    # Windows
netstat -an | findstr :11434   # Windows
lsof -i :5006                  # Mac/Linux
lsof -i :11434                 # Mac/Linux

# Matar processos se necess√°rio
taskkill /F /PID [PID]         # Windows
kill -9 [PID]                 # Mac/Linux
```

### ‚ùå AI n√£o classifica transa√ß√µes
```bash
# 1. Verificar logs
yarn ai:dev:logs

# 2. Verificar se proxy est√° funcionando
curl http://localhost:11434/health

# 3. Verificar configura√ß√µes
cat .env.addon

# 4. Reiniciar tudo
yarn ai:dev:stop
yarn start:server-dev-ai
```

### ‚ùå Budget ID incorreto
1. No Actual: **Configura√ß√µes** ‚Üí **Show advanced settings**
2. Copie o **Sync ID** completo (formato: `uuid-completo`)
3. Cole exatamente no `.env.addon`
4. **Importante**: Sync ID ‚â† Database ID

### ‚ùå Proxy n√£o responde
```bash
# Verificar se est√° rodando
docker ps | grep claude-code-proxy

# Verificar logs do proxy
docker-compose -f docker-compose.dev.yml logs claude-code-proxy

# Rebuild se necess√°rio
docker-compose -f docker-compose.dev.yml build claude-code-proxy
```

### ‚ùå Permiss√µes Docker (Linux/Mac)
```bash
# Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER

# Reiniciar sess√£o ou executar
newgrp docker
```

## üìö Documenta√ß√£o

- **[COMO-USAR.md](./COMO-USAR.md)** - Guia completo de uso
- **[CLAUDE.md](./CLAUDE.md)** - Refer√™ncia de desenvolvimento
- **[claude-code-proxy/](./claude-code-proxy/)** - Documenta√ß√£o t√©cnica dos experimentos

## ‚ö†Ô∏è Aviso Importante

Este √© um **fork experimental** apenas para:
- üß™ Testes pessoais de funcionalidades
- üî¨ Experimenta√ß√£o com IA
- üìö Aprendizado de desenvolvimento

**Para uso em produ√ß√£o**, use o projeto oficial: https://github.com/actualbudget/actual

## üîó Links √öteis

- **Projeto Original**: [Actual Budget](https://github.com/actualbudget/actual)
- **Documenta√ß√£o Oficial**: [actualbudget.org/docs](https://actualbudget.org/docs)
- **Comunidade**: [Discord](https://discord.gg/pRYNYr4W5A)

## üìÑ Licen√ßa

MIT License - Mesmo do projeto original [Actual Budget](https://github.com/actualbudget/actual)
